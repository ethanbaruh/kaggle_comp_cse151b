{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ebde34",
   "metadata": {},
   "source": [
    "**Model Config**\n",
    "Use Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03d65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import data_module as dm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SOS = 0\n",
    "EOS = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58638407",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n",
    "\n",
    "- Load CSV file dataset\n",
    "- Create Torch Dataset\n",
    "- Create Torch DataLoader\n",
    "- Create padding func (with insertion of SOS and EOS tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d4005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl, train_len, test_len = dm.get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693bd733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 64, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_dl)\n",
    "fs = next(it)\n",
    "fs = fs[1]\n",
    "fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82379ba",
   "metadata": {},
   "source": [
    "**Model Building**\n",
    "- Encoder-Decoder architecture\n",
    "    - Encoder -> MLP or CNN\n",
    "    - Decoder -> LSTM RNN\n",
    "    - Batch Normalization in both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6622884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Architectures \"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(594, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(input.float()))))\n",
    "        x = self.dropout(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = x.view(1, -1, 128)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845ec1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(1, 128)\n",
    "        \n",
    "    def forward(self, in_feats, hidden):\n",
    "        do, hidden = self.gru(in_feats.to(torch.float), hidden.to(torch.float))\n",
    "        do = torch.sigmoid(do)\n",
    "        \n",
    "        return do, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17088fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487168\n",
      "50304\n",
      "444161\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "pred = Pred()\n",
    "print(sum(p.numel() for p in enc.parameters() if p.requires_grad))\n",
    "print(sum(p.numel() for p in dec.parameters() if p.requires_grad))\n",
    "print(sum(p.numel() for p in pred.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081c2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pred(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pred, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(128+594, 512) # Take in 128 feats from gru hidden plus categoricals\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "    def forward(self, in_feats):\n",
    "        x = self.dropout(F.relu(self.fc1(in_feats)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = (self.sig(self.fc7(x)) * 2 * 716.4264615618442) % (716.4264615618442 + 2*684.7511617508213)\n",
    "        x = x - (x % 15)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62bbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSE, self).__init__()\n",
    "        \n",
    "        self.crit = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return torch.sqrt(self.crit(x.squeeze(0).to(torch.float64), y.squeeze(0).to(torch.float64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ede66",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "313b17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer helper functions from \n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s' % (asMinutes(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cafa9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(in_feats, cl, tt, encoder, decoder, pred, enc_optim, dec_optim, pred_optim, criterion):\n",
    "    enc_optim.zero_grad()\n",
    "    dec_optim.zero_grad()\n",
    "    pred_optim.zero_grad()\n",
    "    \n",
    "    in_feats = in_feats.to(device)\n",
    "    cl = cl.to(device)\n",
    "    tt = tt.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    hidden = encoder(in_feats)\n",
    "    \n",
    "    \n",
    "    di = cl[0].unsqueeze(0).to(device)\n",
    "    dh = hidden.to(device)\n",
    "                    \n",
    "    use_teacher_forcing = True if random.random() < 0.5 else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(len(cl) - 1):\n",
    "            do, dh = decoder(di, dh)\n",
    "            di = cl[i + 1].unsqueeze(0).to(device)  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(len(cl)):\n",
    "            do, dh = decoder(di, dh)\n",
    "            \n",
    "            topv, topi = do.topk(1, dim=2)\n",
    "            di = topv.detach().to(device)  # detach from history as input\n",
    "\n",
    "\n",
    "    pred_in = torch.cat((in_feats.squeeze(0), dh.squeeze(0)), dim=1).to(device)\n",
    "\n",
    "    pred_time = pred(pred_in)\n",
    "    loss += criterion(pred_time, tt.unsqueeze(0).unsqueeze(-1))\n",
    "    loss.backward()\n",
    "        \n",
    "    enc_optim.step()\n",
    "    dec_optim.step()\n",
    "    pred_optim.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb3f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, predictor, n_epochs, print_every=1000, eval_every = 5, learning_rate=0.003):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    enc_optim = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    dec_optim = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    pred_optim = optim.Adam(predictor.parameters(), lr=learning_rate)\n",
    "    criterion = RMSE()\n",
    "    es = optim.lr_scheduler.ReduceLROnPlateau(enc_optim, 'min', 0.25, 3)\n",
    "    ds = optim.lr_scheduler.ReduceLROnPlateau(dec_optim, 'min', 0.25, 3)\n",
    "    ps = optim.lr_scheduler.ReduceLROnPlateau(pred_optim, 'min', 0.25, 3)\n",
    "\n",
    "    \n",
    "    epoch_loss_max = math.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i, data in enumerate(train_dl):\n",
    "\n",
    "            in_feats = data[0] # back to data\n",
    "\n",
    "            if (in_feats.shape[0] != 64):\n",
    "                continue\n",
    "\n",
    "            cl = data[1] # back to data\n",
    "            tt = data[2] # back to data\n",
    "            loss = train(in_feats, cl, tt, encoder, decoder, pred, enc_optim, dec_optim, pred_optim, criterion)\n",
    "            print_loss_total += loss\n",
    "\n",
    "\n",
    "            if (i % 1000 == 0):\n",
    "                if (print_loss_total < epoch_loss_max):\n",
    "                    epoch_loss_max = print_loss_total\n",
    "                    torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'encoder_state_dict': encoder.state_dict(),\n",
    "                            'encoder_optimizer_state_dict': enc_optim.state_dict(),\n",
    "                            'decoder_state_dict': decoder.state_dict(),\n",
    "                            'decoder_optimizer_state_dict': dec_optim.state_dict(),\n",
    "                            'loss': print_loss_total,\n",
    "                            }, 'model.pt')\n",
    "\n",
    "            if (i % print_every == 0) and (i != 0): # Change back to i\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "\n",
    "\n",
    "\n",
    "                print('Epoch: %d Elapsed: %s Percent of epoch Complete: (%d%%) %.4f' % (epoch, timeSince(start, i / (train_len / 128)),\n",
    "                                                                  i / (train_len / 64) * 100, print_loss_avg))\n",
    "\n",
    "\n",
    "            if (i % eval_every == 0) and (i != 0):\n",
    "                print('*****EVALUATING*****')\n",
    "                eval_loss = eval_epoch(encoder, decoder, pred, epoch)\n",
    "                es.step(eval_loss)\n",
    "                ds.step(eval_loss)\n",
    "                ps.step(eval_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258893e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, pred, in_feats, cl, tt, max_len=1500):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        eval_loss = RMSE()\n",
    "        in_feats = in_feats.to(device)\n",
    "        cl = cl.to(device)\n",
    "        tt = tt.to(device)\n",
    "\n",
    "        hidden = encoder(in_feats)\n",
    "\n",
    "\n",
    "        di = torch.zeros((1,64,1)).to(device)\n",
    "        dh = hidden.to(device)\n",
    "\n",
    "        for i in range(1000):\n",
    "            do, dh = dec(di, dh)\n",
    "\n",
    "            topv, topi = do.topk(1, dim=2)\n",
    "            di = topv.detach().to(device)  # detach from history as input\n",
    "            \n",
    "\n",
    "        pred_in = torch.cat((in_feats.squeeze(0), dh.squeeze(0)), dim=1).to(device)\n",
    "        pred_time = pred(pred_in)\n",
    "        \n",
    "        l = eval_loss(pred_time, tt.unsqueeze(0).unsqueeze(-1))\n",
    "        \n",
    "        return l\n",
    "    \n",
    "def eval_epoch(encoder, decoder, pred, epoch):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    pred.eval()\n",
    "\n",
    "    accs = []\n",
    "    for i, data in enumerate(test_dl):\n",
    "        in_feats = data[0]\n",
    "        if (in_feats.shape[0] != 64):\n",
    "            continue\n",
    "        cl = data[1]\n",
    "        tt = data[2]\n",
    "        accs.append(evaluate(encoder, decoder, pred, in_feats, cl, tt))\n",
    "        \n",
    "        if (i > 100):\n",
    "            break\n",
    "    \n",
    "    epoch_acc = (sum(accs) / len(accs)) if len(accs) > 0 else 0\n",
    "    print('Epoch: %d, Loss on test: %.4f' % (epoch, epoch_acc))\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    pred.train()\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b391701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Elapsed: 0m 0s Percent of epoch Complete: (1%) 488.3106\n",
      "Epoch: 0 Elapsed: 0m 1s Percent of epoch Complete: (2%) 470.6309\n",
      "Epoch: 0 Elapsed: 0m 2s Percent of epoch Complete: (3%) 486.8179\n",
      "Epoch: 0 Elapsed: 0m 3s Percent of epoch Complete: (5%) 470.8226\n",
      "Epoch: 0 Elapsed: 0m 4s Percent of epoch Complete: (6%) 473.9658\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 495.3253\n",
      "Epoch: 0 Elapsed: 0m 25s Percent of epoch Complete: (7%) 474.4387\n",
      "Epoch: 0 Elapsed: 0m 26s Percent of epoch Complete: (8%) 478.4803\n",
      "Epoch: 0 Elapsed: 0m 27s Percent of epoch Complete: (10%) 470.8929\n",
      "Epoch: 0 Elapsed: 0m 28s Percent of epoch Complete: (11%) 454.7578\n",
      "Epoch: 0 Elapsed: 0m 29s Percent of epoch Complete: (12%) 501.2186\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 439.1780\n",
      "Epoch: 0 Elapsed: 0m 50s Percent of epoch Complete: (14%) 461.7134\n",
      "Epoch: 0 Elapsed: 0m 51s Percent of epoch Complete: (15%) 483.4835\n",
      "Epoch: 0 Elapsed: 0m 52s Percent of epoch Complete: (16%) 455.2790\n",
      "Epoch: 0 Elapsed: 0m 53s Percent of epoch Complete: (17%) 491.2371\n",
      "Epoch: 0 Elapsed: 0m 54s Percent of epoch Complete: (19%) 448.4347\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 473.1029\n",
      "Epoch: 0 Elapsed: 1m 15s Percent of epoch Complete: (20%) 480.9398\n",
      "Epoch: 0 Elapsed: 1m 16s Percent of epoch Complete: (21%) 488.4544\n",
      "Epoch: 0 Elapsed: 1m 17s Percent of epoch Complete: (23%) 424.9977\n",
      "Epoch: 0 Elapsed: 1m 18s Percent of epoch Complete: (24%) 480.9322\n",
      "Epoch: 0 Elapsed: 1m 19s Percent of epoch Complete: (25%) 444.6984\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 476.1299\n",
      "Epoch: 0 Elapsed: 1m 40s Percent of epoch Complete: (26%) 552.1477\n",
      "Epoch: 0 Elapsed: 1m 41s Percent of epoch Complete: (28%) 462.6650\n",
      "Epoch: 0 Elapsed: 1m 42s Percent of epoch Complete: (29%) 459.1625\n",
      "Epoch: 0 Elapsed: 1m 43s Percent of epoch Complete: (30%) 484.7761\n",
      "Epoch: 0 Elapsed: 1m 43s Percent of epoch Complete: (32%) 441.2723\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 466.5163\n",
      "Epoch: 0 Elapsed: 2m 5s Percent of epoch Complete: (33%) 490.6955\n",
      "Epoch: 0 Elapsed: 2m 6s Percent of epoch Complete: (34%) 442.9101\n",
      "Epoch: 0 Elapsed: 2m 7s Percent of epoch Complete: (35%) 454.8567\n",
      "Epoch: 0 Elapsed: 2m 8s Percent of epoch Complete: (37%) 473.2148\n",
      "Epoch: 0 Elapsed: 2m 8s Percent of epoch Complete: (38%) 486.9427\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 473.4093\n",
      "Epoch: 0 Elapsed: 2m 30s Percent of epoch Complete: (39%) 499.9608\n",
      "Epoch: 0 Elapsed: 2m 31s Percent of epoch Complete: (40%) 504.1029\n",
      "Epoch: 0 Elapsed: 2m 31s Percent of epoch Complete: (42%) 463.8374\n",
      "Epoch: 0 Elapsed: 2m 32s Percent of epoch Complete: (43%) 540.4934\n",
      "Epoch: 0 Elapsed: 2m 33s Percent of epoch Complete: (44%) 493.6881\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 496.9665\n",
      "Epoch: 0 Elapsed: 2m 55s Percent of epoch Complete: (46%) 482.4056\n",
      "Epoch: 0 Elapsed: 2m 55s Percent of epoch Complete: (47%) 460.1231\n",
      "Epoch: 0 Elapsed: 2m 56s Percent of epoch Complete: (48%) 486.4321\n",
      "Epoch: 0 Elapsed: 2m 57s Percent of epoch Complete: (49%) 499.3472\n",
      "Epoch: 0 Elapsed: 2m 58s Percent of epoch Complete: (51%) 474.8685\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 471.1800\n",
      "Epoch: 0 Elapsed: 3m 20s Percent of epoch Complete: (52%) 441.2563\n",
      "Epoch: 0 Elapsed: 3m 21s Percent of epoch Complete: (53%) 444.5802\n",
      "Epoch: 0 Elapsed: 3m 21s Percent of epoch Complete: (55%) 456.2836\n",
      "Epoch: 0 Elapsed: 3m 22s Percent of epoch Complete: (56%) 504.7248\n",
      "Epoch: 0 Elapsed: 3m 23s Percent of epoch Complete: (57%) 470.6470\n",
      "*****EVALUATING*****\n",
      "Epoch: 0, Loss on test: 448.6591\n",
      "Epoch: 0 Elapsed: 3m 45s Percent of epoch Complete: (58%) 468.9340\n",
      "Epoch: 0 Elapsed: 3m 46s Percent of epoch Complete: (60%) 455.7797\n",
      "Epoch: 0 Elapsed: 3m 46s Percent of epoch Complete: (61%) 437.0940\n",
      "Epoch: 0 Elapsed: 3m 47s Percent of epoch Complete: (62%) 497.2786\n",
      "Epoch: 0 Elapsed: 3m 48s Percent of epoch Complete: (64%) 462.6949\n",
      "*****EVALUATING*****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31949/2288450287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainEpochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31949/3922341990.py\u001b[0m in \u001b[0;36mtrainEpochs\u001b[0;34m(encoder, decoder, predictor, n_epochs, print_every, eval_every, learning_rate)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*****EVALUATING*****'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31949/409597533.py\u001b[0m in \u001b[0;36meval_epoch\u001b[0;34m(encoder, decoder, pred, epoch)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31949/409597533.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, pred, in_feats, cl, tt, max_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31949/1636091167.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_feats, hidden)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n",
    "pred = Pred().to(device)\n",
    "\n",
    "trainEpochs(enc, dec, pred, 1, print_every=50, eval_every = 250, learning_rate = 0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5debfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(enc, dec, pred):\n",
    "    test_dl, test_len = dm.get_loader(test=True)\n",
    "    trip_ids = []\n",
    "    pred_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        pred.eval()\n",
    "        for i, (trip_id, in_feats) in enumerate(test_dl):\n",
    "            in_feats = in_feats.to(device)\n",
    "            \n",
    "            hidden = enc(in_feats)\n",
    "\n",
    "            di = torch.Tensor([0]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            dh = hidden.to(device)\n",
    "                                \n",
    "            for i in range(12):\n",
    "                do, dh = dec(di, dh)\n",
    "            \n",
    "                topv, topi = do.topk(1, dim=2)\n",
    "                di = topv.detach().to(device)  # detach from history as input\n",
    "                if (topv == EOS):\n",
    "                    break\n",
    "            \n",
    "            pred_in = torch.cat((in_feats, dh.squeeze(0)), dim=1).to(device)\n",
    "            pred_time = pred(pred_in)\n",
    "            trip_ids.append(trip_id[0])\n",
    "            pred_times.append(pred_time.item())\n",
    "\n",
    "    df_sample = pd.read_csv(\"data/sampleSubmission.csv\")\n",
    "    df_sample[\"TRAVEL_TIME\"] = pred_times\n",
    "    df_sample.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13e64d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(enc, dec, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68606be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747bc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
