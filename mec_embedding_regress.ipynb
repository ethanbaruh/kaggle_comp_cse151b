{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ebde34",
   "metadata": {},
   "source": [
    "**Model Config**\n",
    "Use Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03d65a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import data_module as dm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SOS = 0\n",
    "EOS = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58638407",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n",
    "\n",
    "- Load CSV file dataset\n",
    "- Create Torch Dataset\n",
    "- Create Torch DataLoader\n",
    "- Create padding func (with insertion of SOS and EOS tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d4005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl, train_len, test_len = dm.get_loader(use_embedding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f05e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 540.,  315.,  510.,  270.,  285.,  885.,  555.,  555.,  375.,  885.,\n",
      "         675.,  930., 1350.,  405.,  825.,  390.,  720.,  645.,  555.,  465.,\n",
      "         255.,  540.,  795.,  780.,  855.,  540.,  315.,  180., 1020.,  345.,\n",
      "         690.,  540.,  270.,  615., 1170.,  885., 1065.,  435., 5100.,  345.,\n",
      "         465., 1695.,  870.,  315.,  795.,  660.,  285., 1140.,  675.,  480.,\n",
      "         270.,  780., 2385.,  525., 1005.,  660.,  855., 1095., 1470.,  405.,\n",
      "         450.,  810., 1530.,  360.])\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dl)\n",
    "fs = next(it)\n",
    "tt = fs[2]\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82379ba",
   "metadata": {},
   "source": [
    "**Model Building**\n",
    "- Encoder-Decoder architecture\n",
    "    - Encoder -> MLP or CNN\n",
    "    - Decoder -> LSTM RNN\n",
    "    - Batch Normalization in both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6622884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Architectures \"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(594, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(input.float()))))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(1, -1, 128)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "845ec1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(len(list(dm.coord_2_idx.keys())), 1024)\n",
    "        self.gru = nn.GRU(1024, 128, num_layers=2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, in_feats, hidden):\n",
    "        embedded = self.emb(in_feats.to(torch.int64)).to(device)\n",
    "        embedded = F.relu(embedded.squeeze(2))\n",
    "        do, hidden = self.gru(embedded, hidden.to(torch.float))\n",
    "        do = self.softmax(do)\n",
    "        \n",
    "        return do, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros((2, 64, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "081c2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pred(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pred, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256+594, 256) # Take in 128 feats from gru hidden plus categoricals\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "        self.sm = nn.Sigmoid()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "    def forward(self, in_feats):\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(in_feats))))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sm(x) * 3 * 716.4264615618442\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d62bbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSE, self).__init__()\n",
    "        \n",
    "        self.crit = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return torch.sqrt(self.crit(x.squeeze(0).to(torch.float64), y.squeeze(0).to(torch.float64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ede66",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "313b17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer helper functions from \n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s' % (asMinutes(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cafa9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(in_feats, cl, tt, encoder, decoder, pred, enc_optim, dec_optim, pred_optim, criterion):\n",
    "    #enc_optim.zero_grad()\n",
    "    dec_optim.zero_grad()\n",
    "    pred_optim.zero_grad()\n",
    "    \n",
    "    in_feats = in_feats.to(device)\n",
    "    cl = cl.to(device)\n",
    "    tt = tt.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    #hidden = encoder(in_feats)\n",
    "    hidden = decoder.init_hidden()\n",
    "    \n",
    "    di = cl[0].unsqueeze(0).to(device)\n",
    "    dh = hidden.to(device)\n",
    "                    \n",
    "    use_teacher_forcing = True if random.random() < 0 else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(len(cl) - 1):\n",
    "            do, dh = decoder(di, dh)\n",
    "            do = do.to(device)\n",
    "            dh = dh.to(device)\n",
    "            di = cl[i + 1].unsqueeze(0).to(device)  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(len(cl)):\n",
    "            do, dh = decoder(di, dh)\n",
    "            do = do.to(device)\n",
    "            dh = dh.to(device)\n",
    "            \n",
    "            topv, topi = do.topk(1, dim=2)\n",
    "            di = topi.detach().to(device)  # detach from history as input\n",
    "\n",
    "    dh = dh.reshape((1, 64, -1))\n",
    "    pred_in = torch.cat((in_feats, dh.squeeze(0)), dim=1).to(device)\n",
    "\n",
    "    pred_time = pred(pred_in)\n",
    "    tt = tt.unsqueeze(-1).to(torch.int64)\n",
    "\n",
    "    loss += criterion(pred_time, tt)\n",
    "    loss.backward()\n",
    "        \n",
    "    #enc_optim.step()\n",
    "    dec_optim.step()\n",
    "    pred_optim.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dfb3f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, predictor, n_epochs, print_every=1000, eval_every = 5, learning_rate=0.003):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    enc_optim = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "    dec_optim = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "    pred_optim = optim.AdamW(predictor.parameters(), lr=learning_rate)\n",
    "    criterion = RMSE()\n",
    "    es = optim.lr_scheduler.ReduceLROnPlateau(enc_optim, 'min', 0.25, 3)\n",
    "    ds = optim.lr_scheduler.ReduceLROnPlateau(dec_optim, 'min', 0.25, 3)\n",
    "    ps = optim.lr_scheduler.ReduceLROnPlateau(pred_optim, 'min', 0.25, 3)\n",
    "\n",
    "    \n",
    "    epoch_loss_max = math.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, data in enumerate(train_dl): # change back to train_dl\n",
    "            if i > 1:\n",
    "                break\n",
    "            in_feats = data[0]\n",
    "\n",
    "            if (in_feats.shape[0] != 64):\n",
    "                continue\n",
    "\n",
    "            cl = data[1]\n",
    "\n",
    "            tt = data[2]\n",
    "            loss = train(in_feats, cl, tt, encoder, decoder, pred, enc_optim, dec_optim, pred_optim, criterion)\n",
    "            print_loss_total += loss\n",
    "\n",
    "\n",
    "            if (i % 1000 == 0):\n",
    "                if (print_loss_total < epoch_loss_max):\n",
    "                    epoch_loss_max = print_loss_total\n",
    "                    torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'encoder_state_dict': encoder.state_dict(),\n",
    "                            'encoder_optimizer_state_dict': enc_optim.state_dict(),\n",
    "                            'decoder_state_dict': decoder.state_dict(),\n",
    "                            'decoder_optimizer_state_dict': dec_optim.state_dict(),\n",
    "                            'loss': print_loss_total,\n",
    "                            }, 'model.pt')\n",
    "\n",
    "            if (i % print_every == 0) and (i != 0): # Change back to i\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "\n",
    "\n",
    "\n",
    "                print('Epoch: %d Elapsed: %s Percent of epoch Complete: (%d%%) %.4f' % (epoch, timeSince(start, i / (train_len / 128)),\n",
    "                                                                  i / (train_len / 64) * 100, print_loss_avg))\n",
    "\n",
    "\n",
    "            if (i % eval_every == 0) and (i != 0):\n",
    "                print('*****EVALUATING*****')\n",
    "                eval_loss = eval_epoch(encoder, decoder, pred, epoch)\n",
    "                es.step(eval_loss)\n",
    "                ds.step(eval_loss)\n",
    "                ps.step(eval_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "258893e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, pred, in_feats, cl, tt, it, max_len=1500):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        eval_loss = RMSE()\n",
    "        in_feats = in_feats.to(device)\n",
    "        cl = cl.to(device)\n",
    "        tt = tt.to(device)\n",
    "\n",
    "        hidden = encoder(in_feats)\n",
    "\n",
    "\n",
    "        di = torch.zeros((1,64,1)).to(device)\n",
    "        dh = hidden.to(device)\n",
    "\n",
    "        for i in range(150):\n",
    "            do, dh = dec(di, dh)\n",
    "\n",
    "            topv, topi = do.topk(1, dim=2)\n",
    "            di = topi.detach().to(device)  # detach from history as input\n",
    "            \n",
    "        pred_in = torch.cat((in_feats.squeeze(0), dh.squeeze(0)), dim=1).to(device)\n",
    "        pred_time = pred(pred_in)\n",
    "        if (it < 1):\n",
    "            print(pred_time)\n",
    "            print(tt)\n",
    "        l = eval_loss(pred_time, tt.unsqueeze(-1).to(torch.int64))\n",
    "        \n",
    "        return l\n",
    "    \n",
    "def eval_epoch(encoder, decoder, pred, epoch):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    pred.eval()\n",
    "\n",
    "    accs = []\n",
    "    for i, data in enumerate(test_dl):\n",
    "        in_feats = data[0]\n",
    "        if (in_feats.shape[0] != 64):\n",
    "            continue\n",
    "        cl = data[1]\n",
    "        tt = data[2]\n",
    "        accs.append(evaluate(encoder, decoder, pred, in_feats, cl, tt, i))\n",
    "        \n",
    "        if (i > 100):\n",
    "            break\n",
    "    \n",
    "    epoch_acc = (sum(accs) / len(accs)) if len(accs) > 0 else 0\n",
    "    print('Epoch: %d, Loss on test: %.4f' % (epoch, epoch_acc))\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    pred.train()\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Elapsed: 0m 4s Percent of epoch Complete: (0%) 1310.2765\n",
      "Epoch: 1 Elapsed: 0m 5s Percent of epoch Complete: (0%) 1446.5200\n",
      "Epoch: 2 Elapsed: 0m 5s Percent of epoch Complete: (0%) 1198.0959\n",
      "Epoch: 3 Elapsed: 0m 8s Percent of epoch Complete: (0%) 1372.3197\n",
      "Epoch: 4 Elapsed: 0m 10s Percent of epoch Complete: (0%) 941.3321\n",
      "Epoch: 5 Elapsed: 0m 11s Percent of epoch Complete: (0%) 1154.8363\n",
      "Epoch: 6 Elapsed: 0m 12s Percent of epoch Complete: (0%) 1069.5322\n",
      "Epoch: 7 Elapsed: 0m 15s Percent of epoch Complete: (0%) 1124.5506\n",
      "Epoch: 8 Elapsed: 0m 17s Percent of epoch Complete: (0%) 1003.0706\n",
      "Epoch: 9 Elapsed: 0m 18s Percent of epoch Complete: (0%) 1122.7804\n",
      "Epoch: 10 Elapsed: 0m 19s Percent of epoch Complete: (0%) 1097.0497\n",
      "Epoch: 11 Elapsed: 0m 22s Percent of epoch Complete: (0%) 918.7956\n",
      "Epoch: 12 Elapsed: 0m 23s Percent of epoch Complete: (0%) 828.2552\n",
      "Epoch: 13 Elapsed: 0m 24s Percent of epoch Complete: (0%) 1197.4323\n",
      "Epoch: 14 Elapsed: 0m 25s Percent of epoch Complete: (0%) 1184.7129\n",
      "Epoch: 15 Elapsed: 0m 25s Percent of epoch Complete: (0%) 812.0362\n",
      "Epoch: 16 Elapsed: 0m 26s Percent of epoch Complete: (0%) 1096.0201\n",
      "Epoch: 17 Elapsed: 0m 27s Percent of epoch Complete: (0%) 960.4912\n",
      "Epoch: 18 Elapsed: 0m 28s Percent of epoch Complete: (0%) 1196.1035\n",
      "Epoch: 19 Elapsed: 0m 29s Percent of epoch Complete: (0%) 1125.2506\n",
      "Epoch: 20 Elapsed: 0m 32s Percent of epoch Complete: (0%) 668.0999\n",
      "Epoch: 21 Elapsed: 0m 32s Percent of epoch Complete: (0%) 942.1859\n",
      "Epoch: 22 Elapsed: 0m 33s Percent of epoch Complete: (0%) 893.6625\n",
      "Epoch: 23 Elapsed: 0m 35s Percent of epoch Complete: (0%) 976.1016\n",
      "Epoch: 24 Elapsed: 0m 36s Percent of epoch Complete: (0%) 886.1416\n",
      "Epoch: 25 Elapsed: 0m 38s Percent of epoch Complete: (0%) 586.9699\n",
      "Epoch: 26 Elapsed: 0m 39s Percent of epoch Complete: (0%) 753.8530\n",
      "Epoch: 27 Elapsed: 0m 39s Percent of epoch Complete: (0%) 1092.6299\n",
      "Epoch: 28 Elapsed: 0m 40s Percent of epoch Complete: (0%) 799.9596\n",
      "Epoch: 29 Elapsed: 0m 41s Percent of epoch Complete: (0%) 744.2057\n",
      "Epoch: 30 Elapsed: 0m 41s Percent of epoch Complete: (0%) 709.9935\n",
      "Epoch: 31 Elapsed: 0m 42s Percent of epoch Complete: (0%) 1216.6453\n",
      "Epoch: 32 Elapsed: 0m 43s Percent of epoch Complete: (0%) 866.9615\n",
      "Epoch: 33 Elapsed: 0m 44s Percent of epoch Complete: (0%) 1013.3872\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n",
    "pred = Pred().to(device)\n",
    "\n",
    "trainEpochs(enc, dec, pred, 100, print_every=1, eval_every = 500, learning_rate = 0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(enc, dec, pred):\n",
    "    test_dl, test_len = dm.get_loader(test=True)\n",
    "    trip_ids = []\n",
    "    pred_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        pred.eval()\n",
    "        for i, (trip_id, in_feats) in enumerate(test_dl):\n",
    "            in_feats = in_feats.to(device)\n",
    "            \n",
    "            hidden = enc(in_feats)\n",
    "\n",
    "            di = torch.Tensor([0]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            dh = hidden.to(device)\n",
    "                                \n",
    "            for i in range(150):\n",
    "                do, dh = dec(di, dh)\n",
    "            \n",
    "                topv, topi = do.topk(1, dim=2)\n",
    "                di = topi.detach().to(device)  # detach from history as input\n",
    "                if (topi == i):\n",
    "                    break\n",
    "                    \n",
    "                if (i > 145):\n",
    "                    print('reached 150')\n",
    "            \n",
    "            pred_in = torch.cat((in_feats, dh.squeeze(0)), dim=1).to(device)\n",
    "            pred_idx = pred(pred_in)\n",
    "            \n",
    "            topv, topi = pred_idx.topk(1, dim=1)\n",
    "            pred_time = dm.i2t[topi.item()]\n",
    "            \n",
    "            trip_ids.append(trip_id[0])\n",
    "            pred_times.append(pred_time)\n",
    "\n",
    "    df_sample = pd.read_csv(\"data/sampleSubmission.csv\")\n",
    "    df_sample[\"TRAVEL_TIME\"] = pred_times\n",
    "    df_sample.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13e64d84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15196/3823445300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "submission(enc, dec, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68606be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747bc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
